# Frank Wolfe for Adversarial Attacks

An educational project inspired be the UniPD course Optimization for Data Science.

We deal with 4 following articles.

## Articles

- Zero-Order Stochastic Conditional Gradient Sliding Method for Non-smooth Convex Optimization [Lobanov 
et al.](https://arxiv.org/abs/2303.02778)
- Can Stochastic Zeroth-Order Frank-Wolfe Method Converge Faster for Non-Convex Problems? [Gao et al.](https://proceedings.mlr.press/v119/gao20b.html)
- Towards Gradient Free and Projection Free Stochastic Optimization [Sahu et al.](http://proceedings.mlr.press/v89/sahu19a.html)

## Task

- analyze in depth the theory of the papers [Sahu et al.] and [Gao et al.]
- develop the codes for the following first-order algorithms: 
(Algorithm 2, Sahu et al.), FZCGS (Gao et al.) and  ZO-SCGS (Lobanov 
et al.)
- test the algorithms on one of the black-box attacks reported in 
Section 4.3 of [Gao et al.]
